# 2025-11-19 작업 내역

## 개요

LLM 서비스 인터페이스 개선 및 프롬프트 관리 로직 중앙화 작업을 진행하였다.

---

## 1. 변경 사항

### LLM Service 리팩토링

| 항목 | 변경 전 | 변경 후 |
|------|---------|---------|
| 함수명 | `create_llm` | `create_llm_router` |
| 에러 처리 | 없음 | try/except + OpenAI fallback |
| Google 지원 | 미지원 | `_create_google()` 추가 |
| Docstring | 기본 | 2배 상세화 |

**관련 파일**: `src/core/llm_service.py`

### Import 경로 업데이트

`create_llm` → `create_llm_router` 변경에 따라 아래 파일들의 import 수정:

- `src/core/graph_factory.py`
- `src/core/__init__.py`
- `src/systems/rag/rag_system_chain.py`
- `src/systems/chat/chat_system_chain.py`

---

## 2. 신규 생성

### PromptsService 클래스

**파일**: `src/core/prompts_service.py`

**목적**: 여러 파일에 분산된 프롬프트 관리 로직을 중앙화

**통합 대상**:
- `graph_factory.py`의 `get_available_prompts()`, `get_prompt_info()`
- `config_prompts.py`의 프롬프트 로딩 로직
- `persona_loader.py`의 일부 기능

**주요 메서드**:

| 메서드 | 설명 |
|--------|------|
| `list_prompts(prompt_type)` | 프롬프트 목록 반환 |
| `list_prompt_files(prompt_type)` | 프롬프트 파일명 목록 반환 |
| `load_prompt(prompt_type, name)` | YAML 프롬프트 로드 |
| `get_prompt_info(prompt_type, name)` | 프롬프트 메타정보 반환 |
| `get_template(prompt_type, name)` | 템플릿 문자열만 반환 |

### Config 추가 항목

**파일**: `src/config/config_model.py`

- `LLMProvider` Enum 추가 (OPENAI, ANTHROPIC, GOOGLE, VLLM)
- `MODEL_CONFIG` 딕셔너리 추가 (모델별 provider 매핑)
- `GOOGLE_API_KEY` 환경변수 추가

---

## 3. 삭제 사항

### graph_factory.py에서 제거된 함수

- `get_available_prompts()` → `PromptsService.list_prompts()`로 대체
- `get_prompt_info()` → `PromptsService.get_prompt_info()`로 대체

### 삭제된 폴더

- `src/services/` - 잘못 생성된 폴더 삭제 (PromptsService는 core 폴더로 이동)

---

## 4. 영향 받는 API 엔드포인트

| 파일 | 변경 내용 |
|------|-----------|
| `src/api/chat_endpoints.py` | PromptsService import 경로 변경 |
| `src/api/rag_endpoints.py` | PromptsService import 경로 변경 |

---

## 5. 설계 결정 사항

1. **별칭 미사용**: `create_llm = create_llm_router` 형태의 별칭 대신 모든 import 경로를 직접 수정
2. **core 폴더 배치**: PromptsService는 핵심 비즈니스 로직이므로 services가 아닌 core 폴더에 배치
3. **Persona 기능 보류**: 기본 채팅 기능 우선, Persona 관련 작업은 추후 진행

---

## 6. graph_factory 리팩토링

### 변경 사항

| 항목 | 변경 전 | 변경 후 |
|------|---------|---------|
| 역할 | Factory + Chatbot Chain 생성 | Router 역할만 수행 |
| 지원 시스템 | chatbot, rag, chat | rag, chat |

### 삭제 항목

**graph_factory.py:**
- `create_chatbot_chain()` 함수 전체
- 관련 import (yaml, ChatPromptTemplate, MessagesPlaceholder, StrOutputParser, RunnableWithMessageHistory 등)
- `GraphFactory.create()`의 "chatbot" 분기

**`__init__.py`:**
- `create_chatbot_chain` export

### 삭제 이유

- 프로젝트 목적: RAG QA System + Agentic Chat System
- 일반 채팅 기능은 불필요하여 Router 역할 단순화

---

## 7. 참고

- vLLM으로 5개 모델을 Docker 환경에서 서빙하는 상황을 고려하여 인터페이스 단순화
- 에러 발생 시 OpenAI로 자동 fallback되도록 안전장치 추가
